{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Graph\n",
    "* Building computational graph\n",
    "* Running computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.Variable(4, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1 = tf.constant(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x*y + x + y + c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To evaluate the graph, you need to open a Tensorflow session & use it init the variables, constant  and evaluate f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.variables.Variable at 0x162dad1fe80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = f.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates the session & deletes it as well\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.variables.Variable at 0x162dad1fe80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'read:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.read_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    v = c1.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)  # Iris Setosa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      n_iter=5, n_jobs=1, penalty=None, random_state=42, shuffle=True,\n",
       "      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "raw = urllib.request.urlopen(IRIS_TRAINING_URL).read()\n",
    "with open(IRIS_TRAINING, \"wb\") as f:\n",
    "    f.write(raw)\n",
    "    \n",
    "raw = urllib.request.urlopen(IRIS_TEST_URL).read()\n",
    "with open(IRIS_TEST, \"wb\") as f:\n",
    "    f.write(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets.\n",
    "training_set = tflearn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TRAINING,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'30,4,setosa,versicolor,virginica\\n5.9,3.0,4.2,1.5,1\\n6.9,3.1,5.4,2.1,2\\n5.1,3.3,1.7,0.5,0\\n6.0,3.4,4.5,1.6,1\\n5.5,2.5,4.0,1.3,1\\n6.2,2.9,4.3,1.3,1\\n5.5,4.2,1.4,0.2,0\\n6.3,2.8,5.1,1.5,2\\n5.6,3.0,4.1,1.3,1\\n6.7,2.5,5.8,1.8,2\\n7.1,3.0,5.9,2.1,2\\n4.3,3.0,1.1,0.1,0\\n5.6,2.8,4.9,2.0,2\\n5.5,2.3,4.0,1.3,1\\n6.0,2.2,4.0,1.0,1\\n5.1,3.5,1.4,0.2,0\\n5.7,2.6,3.5,1.0,1\\n4.8,3.4,1.9,0.2,0\\n5.1,3.4,1.5,0.2,0\\n5.7,2.5,5.0,2.0,2\\n5.4,3.4,1.7,0.2,0\\n5.6,3.0,4.5,1.5,1\\n6.3,2.9,5.6,1.8,2\\n6.3,2.5,4.9,1.5,1\\n5.8,2.7,3.9,1.2,1\\n6.1,3.0,4.6,1.4,1\\n5.2,4.1,1.5,0.1,0\\n6.7,3.1,4.7,1.5,1\\n6.7,3.3,5.7,2.5,2\\n6.4,2.9,4.3,1.3,1\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlopen(IRIS_TEST_URL).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TEST,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_environment': 'local', '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000162DEE14780>, '_task_id': 0, '_tf_random_seed': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_task_type': None, '_keep_checkpoint_max': 5, '_evaluation_master': '', '_is_chief': True}\n"
     ]
    }
   ],
   "source": [
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[10, 20, 10],\n",
    "                                              n_classes=3,\n",
    "                                              model_dir=\"D:\\iris_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'hidden_units': [10, 20, 10], 'gradient_clip_norm': None, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x00000162DEE14898>, 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'embedding_lr_multipliers': None, 'activation_fn': <function relu at 0x00000162D96CF400>, 'input_layer_min_slice_size': None, 'dropout': None})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Define the training inputs\n",
    "def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ZekeLabs\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into D:\\iris_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.21355, step = 1\n",
      "INFO:tensorflow:global_step/sec: 368.653\n",
      "INFO:tensorflow:loss = 0.163439, step = 101\n",
      "INFO:tensorflow:global_step/sec: 372.792\n",
      "INFO:tensorflow:loss = 0.0753039, step = 201\n",
      "INFO:tensorflow:global_step/sec: 367.975\n",
      "INFO:tensorflow:loss = 0.0621441, step = 301\n",
      "INFO:tensorflow:global_step/sec: 369.338\n",
      "INFO:tensorflow:loss = 0.0571188, step = 401\n",
      "INFO:tensorflow:global_step/sec: 377.015\n",
      "INFO:tensorflow:loss = 0.0548055, step = 501\n",
      "INFO:tensorflow:global_step/sec: 358.542\n",
      "INFO:tensorflow:loss = 0.052292, step = 601\n",
      "INFO:tensorflow:global_step/sec: 369.338\n",
      "INFO:tensorflow:loss = 0.0504672, step = 701\n",
      "INFO:tensorflow:global_step/sec: 363.28\n",
      "INFO:tensorflow:loss = 0.0491761, step = 801\n",
      "INFO:tensorflow:global_step/sec: 353.621\n",
      "INFO:tensorflow:loss = 0.0477066, step = 901\n",
      "INFO:tensorflow:global_step/sec: 365.281\n",
      "INFO:tensorflow:loss = 0.0466106, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 374.892\n",
      "INFO:tensorflow:loss = 0.0454989, step = 1101\n",
      "INFO:tensorflow:global_step/sec: 377.73\n",
      "INFO:tensorflow:loss = 0.0447128, step = 1201\n",
      "INFO:tensorflow:global_step/sec: 347.461\n",
      "INFO:tensorflow:loss = 0.0436611, step = 1301\n",
      "INFO:tensorflow:global_step/sec: 374.894\n",
      "INFO:tensorflow:loss = 0.0428451, step = 1401\n",
      "INFO:tensorflow:global_step/sec: 394.933\n",
      "INFO:tensorflow:loss = 0.0420962, step = 1501\n",
      "INFO:tensorflow:global_step/sec: 386.508\n",
      "INFO:tensorflow:loss = 0.0413121, step = 1601\n",
      "INFO:tensorflow:global_step/sec: 378.459\n",
      "INFO:tensorflow:loss = 0.0405825, step = 1701\n",
      "INFO:tensorflow:global_step/sec: 382.807\n",
      "INFO:tensorflow:loss = 0.0399019, step = 1801\n",
      "INFO:tensorflow:global_step/sec: 387.266\n",
      "INFO:tensorflow:loss = 0.0392098, step = 1901\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into D:\\iris_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0384892.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'hidden_units': [10, 20, 10], 'gradient_clip_norm': None, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x00000162DEE14898>, 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'embedding_lr_multipliers': None, 'activation_fn': <function relu at 0x00000162D96CF400>, 'input_layer_min_slice_size': None, 'dropout': None})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model.\n",
    "classifier.fit(input_fn=get_train_inputs, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the test inputs\n",
    "def get_test_inputs():\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ZekeLabs\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-05-29-03:44:05\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-05-29-03:44:07\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.966667, auc = 0.998333, global_step = 2000, loss = 0.069797\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=get_test_inputs,\n",
    "                                       steps=1)[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
